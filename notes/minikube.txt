To enable auto-scaling and load balancing for your microservices, you can use Kubernetes. Kubernetes provides built-in mechanisms for load balancing and auto-scaling based on resource usage. Here’s how you can set it up:

### 1. **Install Kubernetes and Minikube**
First, ensure you have Kubernetes installed on your Ubuntu server. You can use Minikube for local development.

```bash
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
minikube start
```

### 2. **Create Docker Images for Each Microservice**
Ensure each microservice has a `Dockerfile` and build the Docker images.

```bash
docker build -t user-service:latest ./user-service
docker build -t product-service:latest ./product-service
# Repeat for other services
```

### 3. **Push Docker Images to a Registry**
Push your Docker images to a container registry like Docker Hub or a private registry.

```bash
docker tag user-service:latest your-dockerhub-username/user-service:latest
docker push your-dockerhub-username/user-service:latest
# Repeat for other services
```

### 4. **Create Kubernetes Deployment and Service Files**
Create deployment and service YAML files for each microservice. Here’s an example for the `user-service`:

```yaml
# user-service-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: user-service
  template:
    metadata:
      labels:
        app: user-service
    spec:
      containers:
      - name: user-service
        image: your-dockerhub-username/user-service:latest
        ports:
        - containerPort: 8081
        resources:
          requests:
            cpu: "100m"
            memory: "256Mi"
          limits:
            cpu: "500m"
            memory: "512Mi"
---
# user-service-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: user-service
spec:
  type: ClusterIP
  selector:
    app: user-service
  ports:
  - port: 8081
    targetPort: 8081
```

### 5. **Deploy to Kubernetes**
Apply the deployment and service files to your Kubernetes cluster.

```bash
kubectl apply -f user-service-deployment.yaml
kubectl apply -f user-service-service.yaml
# Repeat for other services
```

### 6. **Set Up Horizontal Pod Autoscaler (HPA)**
Configure HPA to automatically scale your microservices based on CPU usage.

```yaml
# user-service-hpa.yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: user-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: user-service
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
```

Apply the HPA configuration:

```bash
kubectl apply -f user-service-hpa.yaml
# Repeat for other services
```

### 7. **Configure Ingress for Load Balancing**
Use an Ingress controller to manage external access to your services.

```yaml
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ecommerce-ingress
spec:
  rules:
  - host: your-domain.com
    http:
      paths:
      - path: /user-service
        pathType: Prefix
        backend:
          service:
            name: user-service
            port:
              number: 8081
      # Add paths for other services
```

Apply the Ingress configuration:

```bash
kubectl apply -f ingress.yaml
```

### 8. **Monitor and Manage Your Cluster**
Use Kubernetes Dashboard or tools like Prometheus and Grafana to monitor and manage your cluster.

```bash
minikube dashboard
```

This setup ensures your microservices are load-balanced and can auto-scale based on demand, providing a robust and scalable architecture for your e-commerce application. If you have any questions or need further assistance, feel free to ask!